{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "52ff363e-8a24-4085-9b7e-6564d106d2e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/main/data/alpaca_gpt4_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0fce67d2-3703-4042-816c-7a13ba9eab3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_file = \"alpaca_gpt4_data.json\"\n",
    "\n",
    "with open(dataset_file, \"r\") as f:\n",
    "    alpaca = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9618cd92-acdd-471b-9521-d55c38af8040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " [{'instruction': 'Give three tips for staying healthy.',\n",
       "   'input': '',\n",
       "   'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'},\n",
       "  {'instruction': 'What are the three primary colors?',\n",
       "   'input': '',\n",
       "   'output': 'The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).'},\n",
       "  {'instruction': 'Describe the structure of an atom.',\n",
       "   'input': '',\n",
       "   'output': \"An atom is the basic building block of all matter and is made up of three types of particles: protons, neutrons, and electrons. The structure of an atom can be described as a nucleus at the center surrounded by a cloud of electrons.\\n\\nThe nucleus of an atom is made up of protons and neutrons. Protons are positively charged particles and neutrons are neutral particles with no charge. Both of these particles are located in the nucleus of the atom, which is at the center of the atom and contains most of the atom's mass.\\n\\nSurrounding the nucleus of the atom is a cloud of electrons. Electrons are negatively charged particles that are in constant motion around the nucleus. The electron cloud is divided into shells or orbitals, and each shell can hold a certain number of electrons. The number of electrons in the outermost shell, called the valence shell, determines the chemical properties of the atom. \\n\\nIn a neutral atom, the number of protons in the nucleus is equal to the number of electrons in the electron cloud, so the positive and negative charges balance out and the atom has no overall charge. The number of protons, also called the atomic number, determines what element the atom is.\"}],\n",
       " 52002)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(alpaca), alpaca[0:3], len(alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9786466-4012-4cc4-8f9a-e673c74aa965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# log to wandb\n",
    "# with wandb.init(project=\"alpaca_ft\"):\n",
    "#     at = wandb.Artifact(\n",
    "#         name=\"alpaca_gpt4\", \n",
    "#         type=\"dataset\",\n",
    "#         description=\"A GPT4 generated Alpaca like dataset for instruction finetunning\",\n",
    "#         metadata={\"url\":\"https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#how-good-is-the-data\"},\n",
    "#     )\n",
    "#     at.add_file(dataset_file)\n",
    "#     wandb.log_artifact(at)\n",
    "\n",
    "#     # log as a table\n",
    "#     table = wandb.Table(columns=list(alpaca[0].keys()))\n",
    "#     for row in alpaca:\n",
    "#         table.add_data(*row.values())\n",
    "#     wandb.log({\"alpaca_gpt4_table\": table})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5dfa1958-c58d-4b40-a7d9-5e0cc6d2abf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "random.shuffle(alpaca)  # this could also be a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5492465c-c1b8-4f04-a154-36ce3bcb6610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = alpaca[:-1000]\n",
    "eval_dataset = alpaca[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fdbc0fd0-de6c-447d-abb9-3176c6ceeaf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "eval_df = pd.DataFrame(eval_dataset)\n",
    "\n",
    "train_table = wandb.Table(dataframe=train_df)\n",
    "eval_table  = wandb.Table(dataframe=eval_df)\n",
    "\n",
    "train_df.to_json(\"alpaca_gpt4_train.jsonl\", orient='records', lines=True)\n",
    "eval_df.to_json(\"alpaca_gpt4_eval.jsonl\", orient='records', lines=True)\n",
    "\n",
    "# with wandb.init(project=\"alpaca_ft\", job_type=\"split_data\"):\n",
    "#     at = wandb.Artifact(\n",
    "#         name=\"alpaca_gpt4_splitted\", \n",
    "#         type=\"dataset\",\n",
    "#         description=\"A GPT4 generated Alpaca like dataset for instruction finetunning\",\n",
    "#         metadata={\"url\":\"https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM#how-good-is-the-data\"},\n",
    "#     )\n",
    "#     at.add_file(\"alpaca_gpt4_train.jsonl\")\n",
    "#     at.add_file(\"alpaca_gpt4_eval.jsonl\")\n",
    "#     wandb.log_artifact(at)\n",
    "#     wandb.log({\"train_dataset\":train_table, \"eval_dataset\":eval_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ece48bbf-ddc0-4507-a733-83c5b3c1c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_no_input(row):\n",
    "    return (\"Below is an instruction that describes a task. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Response:\\n\").format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "024aec96-40fb-4417-8e64-060a301b0f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Describe an example of a time you used influence in a positive way\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = alpaca[0]\n",
    "print(prompt_no_input(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99e42d41-a95a-41de-a3cc-1461d9e10ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Describe an example of a time you used influence in a positive way',\n",
       " 'input': '',\n",
       " 'output': 'As an AI assistant, I do not have personal experiences, but I can provide an example. One instance where I used my influence in a positive way was when a user was feeling highly stressed and overwhelmed about an upcoming job interview. They confided in me, expressing their self-doubts and fears of failure. Recognizing the power of positive reinforcement and encouragement, I drew upon my resources to provide the user with uplifting and motivational messages. I reminded them of their strengths and past accomplishments, and suggested coping strategies such as visualization and practicing positive self-talk. Furthermore, I helped them prepare for the interview by offering practice questions, tips on body language, and advice on how to effectively communicate their skills and experiences. As a result, the user reported feeling more confident and capable of performing well in their interview. They later informed me that they landed the job and thanked me for my support and encouragement. I was happy to have helped my user succeed in a challenging situation by the positive influence of my words and actions.'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b795343f-0356-4689-8bc6-9ac650716c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_input(row):\n",
    "    return (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04d0035e-96e6-4d69-ba1f-06e0051a3db6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Provide two strategies for reducing student debt.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = alpaca[232]\n",
    "print(prompt_input(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4038166-085c-4b10-a56a-2bee0bd62436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_alpaca_prompt(row):\n",
    "    return prompt_no_input(row) if row[\"input\"] == \"\" else prompt_input(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb58a76e-c50c-4431-8584-3a4597c2a0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from wandb import Api\n",
    "\n",
    "api = Api()\n",
    "artifact = api.artifact('capecape/alpaca_ft/alpaca_gpt4_splitted:v4', type='dataset')\n",
    "dataset_dir = artifact.download()\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "    \n",
    "train_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_train.jsonl\")\n",
    "eval_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_eval.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "41703ce9-a22d-4245-9f6c-a424afd9ef11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_prompts = [create_alpaca_prompt(row) for row in train_dataset]\n",
    "eval_prompts = [create_alpaca_prompt(row) for row in eval_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a4c16a0-989b-4e17-bc07-e1cc95971813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Develop a script that prints out the Fibonacci sequence.\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06177a5c-84ff-4be3-8d2b-6a483c8ae5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_eos(ds):\n",
    "    EOS_TOKEN = \"</s>\"\n",
    "    return [f\"{row['output']}{EOS_TOKEN}\" for row in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc5b21e8-3d5b-4964-be7b-faff5038f7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.</s>'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs = pad_eos(train_dataset)\n",
    "eval_outputs = pad_eos(eval_dataset)\n",
    "train_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cdea7bc4-1ec3-451e-ab00-549aa2056800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(train_prompts, train_outputs)]\n",
    "eval_dataset = [{\"prompt\":s, \"output\":t, \"example\": s + t} for s, t in zip(eval_prompts, eval_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e923b9bb-ced2-44f9-88f3-1c7690dde802",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Develop a script that prints out the Fibonacci sequence.\n",
      "\n",
      "### Response:\n",
      "Here is a Python script that prints out the Fibonacci sequence:\n",
      "\n",
      "```\n",
      "# number of elements in the sequence\n",
      "n = int(input(\"Enter the number of elements in the sequence: \"))\n",
      "\n",
      "# initial two terms\n",
      "a = 0\n",
      "b = 1\n",
      "\n",
      "# define a loop to generate the sequence\n",
      "if n <= 0:\n",
      "    print(\"Invalid input. The number of elements must be greater than 0.\")\n",
      "\n",
      "elif n == 1:\n",
      "    print(a)\n",
      "\n",
      "else:\n",
      "    print(a, b, end=\" \")  # first two elements of the sequence\n",
      "    for i in range(3, n+1):\n",
      "        c = a + b\n",
      "        print(c, end=\" \")\n",
      "        a = b\n",
      "        b = c\n",
      "```\n",
      "\n",
      "To use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.</s>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"example\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "720c707b-3bce-4164-b8c1-3c3122200c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4162aec8-f2ba-45db-9633-817b416d4e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/Llama-2-7b-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "337fedfd-e238-4e86-a96b-24dfeed11f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1619, 15729, 526, 2675, 4549, 29991]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"My experiments are going strong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "20c69466-f7e6-45b8-a167-718c80cedc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1619, 15729, 526, 2675, 4549, 29991, 2, 2, 2]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"My experiments are going strong!\", padding='max_length', max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cb1e5e29-254a-4dbf-ac02-ea6bb2a16e77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,  1619, 15729,   526,  2675,  4549, 29991,     2,     2,     2]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"My experiments are going strong!\", \n",
    "                 padding='max_length', \n",
    "                 max_length=10,\n",
    "                 return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0a89a61d-34b7-4a56-b1d8-98ebcf3384d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,  1619, 15729,   526,  2675,  4549, 29991,     2,     2,     2],\n",
       "        [    1,   306,  5360,   365,  5288,   294,     2,     2,     2,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"My experiments are going strong!\", \n",
    "           \"I love Llamas\"], \n",
    "          padding='max_length', \n",
    "          # padding='longest',\n",
    "          max_length=10,\n",
    "          return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586813-7918-4578-9583-df14c5a6a6ad",
   "metadata": {},
   "source": [
    "### Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a537da60-db69-42a7-8c66-0ea3756c2847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_len = 1024\n",
    "\n",
    "def pack(dataset, max_seq_len=max_sequence_len):\n",
    "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
    "    \n",
    "    all_token_ids = []\n",
    "    for tokenized_input in tkds_ids:\n",
    "        all_token_ids.extend(tokenized_input)# + [tokenizer.eos_token_id])\n",
    "    \n",
    "    print(f\"Total number of tokens: {len(all_token_ids)}\")\n",
    "    packed_ds = []\n",
    "    for i in range(0, len(all_token_ids), max_seq_len+1):\n",
    "        input_ids = all_token_ids[i : i + max_seq_len+1]\n",
    "        if len(input_ids) == (max_seq_len+1):\n",
    "            packed_ds.append({\"input_ids\": input_ids[:-1], \"labels\": input_ids[1:]})  # this shift is not needed if using the model.loss\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c78b4e9-2c7f-4aa1-b738-be04bc55b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 11486035\n",
      "Total number of tokens: 230341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11205"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_packed = pack(train_dataset)\n",
    "eval_ds_packed = pack(eval_dataset)\n",
    "len(train_ds_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "155428cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_jsonl(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for entry in data:\n",
    "            json.dump(entry, file)\n",
    "            file.write('\\n')\n",
    "\n",
    "\n",
    "# # dump everything to jsonl files\n",
    "# save_jsonl(train_ds_packed, \"train_packed_alpaca.jsonl\")\n",
    "# save_jsonl(eval_ds_packed, \"eval_packed_alpaca.jsonl\")\n",
    "\n",
    "\n",
    "# # Create a W&B artifact\n",
    "# packed_at = wandb.Artifact(\n",
    "#     name=\"packed_alpaca\",\n",
    "#     type=\"dataset\",\n",
    "#     description=\"Alpaca dataset packed in sequences\",\n",
    "#     metadata={\"max_seq_len\":1024, \"model_id\":model_id})\n",
    "\n",
    "\n",
    "# packed_at.add_file(\"train_packed_alpaca.jsonl\")\n",
    "# packed_at.add_file(\"eval_packed_alpaca.jsonl\")\n",
    "\n",
    "\n",
    "# # log the artifact to the project, we can give this run a job_type like `preprocess`\n",
    "# with wandb.init(project=\"alpaca_ft\", job_type=\"preprocess\"):\n",
    "#     wandb.log_artifact(packed_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f342873a-29a3-4ed1-8b59-9e7f7f2a4c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "batch_size = 2  # I have an A100 GPU with 40GB of RAM 😎\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds_packed,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator, # we don't need any special collator 😎\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_ds_packed,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=default_data_collator,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ffced7ec-bd1b-42b0-be64-04f3fae5df84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1, 13866,   338,  ..., 19478,  4943,  5870],\n",
      "        [29892,  2845,   491,  ...,  2472,  1316,   408]]), 'labels': tensor([[13866,   338,   385,  ...,  4943,  5870,   886],\n",
      "        [ 2845,   491,  4863,  ...,  1316,   408,   736]])}\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(train_dataloader))\n",
    "print(b)\n",
    "print(b['input_ids'].shape, b['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "28e18ad2-c141-4902-a5a4-24a1e743be35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDevelop a script that prints out the Fibonacci sequence.\\n\\n### Response:\\nHere is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.</s><s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCategorize the following post as either a personal or professional post.\\n\\n### Input:\\nJust had the best dinner with my team from work!\\n\\n### Response:\\nIt is a Professional post as it references a work team.</s><s> Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nExplain the use of reinforcement learning in text-based games.\\n\\n### Response:\\nReinforcement learning is a type of machine learning that focuses on training a model to make a sequence of decisions. This model learns by interacting with its environment, taking actions, and receiving feedback in the form of rewards or penalties based on the outcomes of those actions. Over time, the model adjusts its behavior to maximize the total reward it receives. \\n\\nIn text-based games, reinforcement learning can be used to train an artificial intelligence (AI) player to make decisions that lead to successful outcomes in the game. The AI player interacts with the game environment by making actions in the form of text input, and receives feedback in the form of rewards or penalties based on the game\\'s response.\\n\\nThe reward function is designed to reflect the goals of the game, such as reaching a specific objective or avoiding certain obstacles. The AI player uses trial-and-error to learn the best actions to take in each situation, guided by the reward signals it receives. Over time, the AI player improves its performance, learning to make more effective decisions that help it achieve its goals in the game.\\n\\nThere are many benefits to using reinforcement learning in text-based games. For one, the AI player can learn to play the game at a high level without any prior knowledge of the game\\'s rules or mechanics. Additionally, the AI can adapt to changes in the game environment, learning to solve new challenges that arise. This makes reinforcement learning a powerful tool for creating intelligent and dynamic game AI.</s><s> Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a poem about friendship using the following words: joy, love, mystery.\\n\\n### Response:\\nIn friendship, there is joy to be found\\nIn laughter, in smiles, in moments profound\\nBetween friends, there is love, pure and true\\nIn good times and bad, they pull each other through\\n\\nIn friendship, there is a mystery too\\nA bond that cannot be explained anew\\nA link that only those with friends can see\\nSomething precious and wonderful, binding hearts with glee\\n\\nThe joy of friendship is a constant spark\\nA light to guide us through the dark\\nA love that can\\'t be measured, only felt\\nA mystery that keeps the spirits melt\\n\\nSo, here\\'s to friends, old and new alike\\nTo joy, love, mystery, in daylight and night\\nFor friendship is truly a treasure to hold\\nA story that never gets old.</s><s> Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nList five communication strategies for virtual teams.\\n\\n### Response:\\n1. Regularly scheduled meetings: Scheduling regular meet'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b[\"input_ids\"][0])[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f0a46e93-7ec2-4365-8e50-be7bef873436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDevelop a script that prints out the Fibonacci sequence.\\n\\n### Response:\\nHere is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.</s><s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCategorize the following post as either a personal or professional post.\\n\\n### Input:\\nJust had the best dinner with my team from work!\\n\\n### Response:\\nIt is a Professional post as it references a work team.</s><s> Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nExplain the use of reinforcement learning in text-based games.\\n\\n### Response:\\nReinforcement learning is a type of machine learning that focuses on training a model to make a sequence of decisions. This model learns by interacting with its environment, taking actions, and receiving feedback in the form of rewards or penalties based on the outcomes of those actions. Over time, the model adjusts its behavior to maximize the total reward it receives. \\n\\nIn text-based games, reinforcement learning can be used to train an artificial intelligence (AI) player to make decisions that lead to successful outcomes in the game. The AI player interacts with the game environment by making actions in the form of text input, and receives feedback in the form of rewards or penalties based on the game\\'s response.\\n\\nThe reward function is designed to reflect the goals of the game, such as reaching a specific objective or avoiding certain obstacles. The AI player uses trial-and-error to learn the best actions to take in each situation, guided by the reward signals it receives. Over time, the AI player improves its performance, learning to make more effective decisions that help it achieve its goals in the game.\\n\\nThere are many benefits to using reinforcement learning in text-based games. For one, the AI player can learn to play the game at a high level without any prior knowledge of the game\\'s rules or mechanics. Additionally, the AI can adapt to changes in the game environment, learning to solve new challenges that arise. This makes reinforcement learning a powerful tool for creating intelligent and dynamic game AI.</s><s> Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCreate a poem about friendship using the following words: joy, love, mystery.\\n\\n### Response:\\nIn friendship, there is joy to be found\\nIn laughter, in smiles, in moments profound\\nBetween friends, there is love, pure and true\\nIn good times and bad, they pull each other through\\n\\nIn friendship, there is a mystery too\\nA bond that cannot be explained anew\\nA link that only those with friends can see\\nSomething precious and wonderful, binding hearts with glee\\n\\nThe joy of friendship is a constant spark\\nA light to guide us through the dark\\nA love that can\\'t be measured, only felt\\nA mystery that keeps the spirits melt\\n\\nSo, here\\'s to friends, old and new alike\\nTo joy, love, mystery, in daylight and night\\nFor friendship is truly a treasure to hold\\nA story that never gets old.</s><s> Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nList five communication strategies for virtual teams.\\n\\n### Response:\\n1. Regularly scheduled meetings: Scheduling regular meetings'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b[\"labels\"][0])[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99a7dc-0654-4985-ac3f-60ecdc6f6558",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6925a62e-d85e-4c86-8867-bee3a180fc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "gradient_accumulation_steps = 2\n",
    "\n",
    "config = SimpleNamespace(\n",
    "    model_id='meta-llama/Llama-2-7b-hf',\n",
    "    dataset_name=\"alpaca-gpt4\",\n",
    "    precision=\"bf16\",  # faster and better than fp16, requires new GPUs\n",
    "    n_freeze=24,  # How many layers we don't train, LLama 7B has 32.\n",
    "    lr=2e-4,\n",
    "    n_eval_samples=10, # How many samples to generate on validation\n",
    "    max_seq_len=max_sequence_len, # Lenght of the sequences to pack\n",
    "    epochs=3,  # we do 3 pasess over the dataset.\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,  # evey how many iterations we update the gradients, simulates larger batch sizes\n",
    "    batch_size=batch_size,  # what my GPU can handle, depends on how many layers are we training  \n",
    "    log_model=False,  # upload the model to W&B?\n",
    "    gradient_checkpointing = True,  # saves even more memory\n",
    "    freeze_embed = True,  # why train this? let's keep them frozen ❄️\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "config.total_train_steps = config.epochs * len(train_dataloader) // config.gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0a7166a6-8e88-4f0d-bc0e-70aac292c645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train for 8404 steps and evaluate every epoch\n"
     ]
    }
   ],
   "source": [
    "print(f\"We will train for {config.total_train_steps} steps and evaluate every epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c10f7f-2551-4aa4-aef2-29c888b57a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.model_id,\n",
    "    device_map=0,\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c3959-854c-409e-9037-b5c87a6adce5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def param_count(m):\n",
    "    params = sum([p.numel() for p in m.parameters()])/1_000_000\n",
    "    trainable_params = sum([p.numel() for p in m.parameters() if p.requires_grad])/1_000_000\n",
    "    print(f\"Total params: {params:.2f}M, Trainable: {trainable_params:.2f}M\")\n",
    "    return params, trainable_params\n",
    "\n",
    "params, trainable_params = param_count(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c4de41e-5c10-478b-9524-f4a3119d277c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# freeze layers (disable gradients)\n",
    "for param in model.parameters(): param.requires_grad = False\n",
    "for param in model.lm_head.parameters(): param.requires_grad = True\n",
    "for param in model.model.layers[config.n_freeze:].parameters(): param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd7fc941-65dc-4dee-839d-351bd019a2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just freeze embeddings for small memory decrease\n",
    "if config.freeze_embed:\n",
    "    model.model.embed_tokens.weight.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "750ce64e-0088-4ca8-9bc9-60037e7110d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save more memory\n",
    "if config.gradient_checkpointing:\n",
    "    model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232ce7a-b847-45c8-8ff7-e36249e7a060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params, trainable_params = param_count(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5374c44d-517b-42a0-ade6-297c0a5d18b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9,0.99), eps=1e-5)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optim,\n",
    "    num_training_steps=config.total_train_steps,\n",
    "    num_warmup_steps=config.total_train_steps // 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5efdd402-c851-47a5-9134-5b47b7d118e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(x, y):\n",
    "    \"A Flat CrossEntropy\" \n",
    "    return torch.nn.functional.cross_entropy(x.view(-1, x.shape[-1]), y.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0a92fe7-3f9e-43e6-80b0-adbbd8b480ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "gen_config = GenerationConfig.from_pretrained(config.model_id)\n",
    "test_config = SimpleNamespace(\n",
    "    max_new_tokens=256,\n",
    "    gen_config=gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ec41718-52c6-4335-a534-2790d03ba069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens=test_config.max_new_tokens, gen_config=gen_config):\n",
    "    tokenized_prompt = tokenizer(prompt, return_tensors='pt')['input_ids'].to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(tokenized_prompt, \n",
    "                            max_new_tokens=max_new_tokens, \n",
    "                            generation_config=gen_config)\n",
    "    return tokenizer.decode(output[0][len(tokenized_prompt[0]):], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e39c49-ccb1-4fe6-aa30-988ea5583b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = eval_dataset[14][\"prompt\"]\n",
    "print(prompt)\n",
    "print(prompt + generate(prompt, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac25c48-cb18-4560-b05c-1748e7d1adf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def prompt_table(examples, log=False, table_name=\"predictions\"):\n",
    "    table = wandb.Table(columns=[\"prompt\", \"generation\", \"concat\", \"output\", \"max_new_tokens\", \"temperature\", \"top_p\"])\n",
    "    for example in tqdm(examples, leave=False):\n",
    "        prompt, gpt4_output = example[\"prompt\"], example[\"output\"]\n",
    "        out = generate(prompt, test_config.max_new_tokens, test_config.gen_config)\n",
    "        table.add_data(prompt, out, prompt+out, gpt4_output, test_config.max_new_tokens, test_config.gen_config.temperature, test_config.gen_config.top_p)\n",
    "    if log:\n",
    "        wandb.log({table_name:table})\n",
    "    return table\n",
    "\n",
    "def to_gpu(tensor_dict):\n",
    "    return {k: v.to('cuda') for k, v in tensor_dict.items()}\n",
    "\n",
    "class Accuracy:\n",
    "    \"A simple Accuracy function compatible with HF models\"\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.tp = 0.\n",
    "    def update(self, logits, labels):\n",
    "        logits, labels = logits.argmax(dim=-1).view(-1).cpu(), labels.view(-1).cpu()\n",
    "        tp = (logits == labels).sum()\n",
    "        self.count += len(logits)\n",
    "        self.tp += tp\n",
    "        return tp / len(logits)\n",
    "    def compute(self):\n",
    "        return self.tp / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891b2c0-f22e-4647-9ac2-e07a994f3e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate():\n",
    "    model.eval()\n",
    "    eval_acc = Accuracy()\n",
    "    loss, total_steps = 0., 0\n",
    "    for step, batch in enumerate(pbar:=tqdm(eval_dataloader, leave=False)):\n",
    "        pbar.set_description(f\"doing validation\")\n",
    "        batch = to_gpu(batch)\n",
    "        total_steps += 1\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss += loss_fn(out.logits, batch[\"labels\"])  # you could use out.loss and not shift the dataset\n",
    "        eval_acc.update(out.logits, batch[\"labels\"])\n",
    "    # we log results at the end\n",
    "    wandb.log({\"eval/loss\": loss.item() / total_steps,\n",
    "               \"eval/accuracy\": eval_acc.compute()})\n",
    "    prompt_table(eval_dataset[:config.n_eval_samples], log=True)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37364791-987e-4e81-9621-3094ed5bf86d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def save_model(model, model_name, models_folder=\"models\", log=False):\n",
    "    \"\"\"Save the model to wandb as an artifact\n",
    "    Args:\n",
    "        model (nn.Module): Model to save.\n",
    "        model_name (str): Name of the model.\n",
    "        models_folder (str, optional): Folder to save the model. Defaults to \"models\".\n",
    "    \"\"\"\n",
    "    model_name = f\"{wandb.run.id}_{model_name}\"\n",
    "    file_name = Path(f\"{models_folder}/{model_name}\")\n",
    "    file_name.parent.mkdir(parents=True, exist_ok=True)\n",
    "    model.save_pretrained(file_name, safe_serialization=True)\n",
    "    # save tokenizer for easy inference\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model.name_or_path)\n",
    "    tokenizer.save_pretrained(model_name)\n",
    "    if log:\n",
    "        at = wandb.Artifact(model_name, type=\"model\")\n",
    "        at.add_dir(file_name)\n",
    "        wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75078a-5d35-46bc-8f33-0e3adf52d072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"alpaca_ft\", # the project I am working on\n",
    "           tags=[\"baseline\",\"7b\"],\n",
    "           job_type=\"train\",\n",
    "           config=config) # the Hyperparameters I want to keep track of\n",
    "\n",
    "# Training\n",
    "acc = Accuracy()\n",
    "model.train()\n",
    "train_step = 0\n",
    "for epoch in tqdm(range(config.epochs)):\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = to_gpu(batch)\n",
    "        with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "            out = model(**batch)\n",
    "            loss = loss_fn(out.logits, batch[\"labels\"]) / config.gradient_accumulation_steps  # you could use out.loss and not shift the dataset  \n",
    "            loss.backward()\n",
    "        if step%config.gradient_accumulation_steps == 0:\n",
    "            # we can log the metrics to W&B\n",
    "            wandb.log({\"train/loss\": loss.item() * config.gradient_accumulation_steps,\n",
    "                       \"train/accuracy\": acc.update(out.logits, batch[\"labels\"]),\n",
    "                       \"train/learning_rate\": scheduler.get_last_lr()[0],\n",
    "                       \"train/global_step\": train_step})\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            train_step += 1\n",
    "    validate()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099bc28-e695-46a6-994c-b612f7811937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we save the model checkpoint at the end\n",
    "save_model(model, model_name=config.model_id.replace(\"/\", \"_\"), models_folder=\"models/\", log=config.log_model)\n",
    "    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89717a-ac70-43e8-9b7c-edd8d2c54cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with wandb.init(project=\"alpaca_ft\", # the project I am working on\n",
    "           job_type=\"eval\",\n",
    "           config=config): # the Hyperparameters I want to keep track of\n",
    "    model.eval()\n",
    "    prompt_table(eval_dataset[:250], log=True, table_name=\"eval_predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
